{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "increased-minutes",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:18.223763Z",
     "iopub.status.busy": "2021-04-29T05:08:18.223056Z",
     "iopub.status.idle": "2021-04-29T05:08:20.454412Z",
     "shell.execute_reply": "2021-04-29T05:08:20.454888Z"
    },
    "papermill": {
     "duration": 2.263873,
     "end_time": "2021-04-29T05:08:20.455067",
     "exception": false,
     "start_time": "2021-04-29T05:08:18.191194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "import pandas as pd\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "import pandas as pd\n",
    "import pickle\n",
    "# pd.set_options(\"display.max_colwidth\",\"None\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7ed2a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "cal=list(calendar.month_name)\n",
    "for i in list(calendar.month_name[1:]):\n",
    "    cal.append(i[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe577e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "da9c6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting tools\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models as gensimvis  \n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-interpretation",
   "metadata": {
    "papermill": {
     "duration": 0.025116,
     "end_time": "2021-04-29T05:08:20.505811",
     "exception": false,
     "start_time": "2021-04-29T05:08:20.480695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ##Topic Modelling: \n",
    "Topic modeling is an unsupervised learning technique used to extract topics from a large corpus of text automatically. Topics can be defined as the co-occurring terms that are frequently repeating in the text corpus. Topic modeling is helpful in various tasks such as clustering documents, understanding and summarizing an extensive collection of textual documents and retrieving information from an extensive collection of data, etc. In this notebook I will perform topic modelling using LDA(Latent Dirichlet Allocation) and BERT. \n",
    "\n",
    "Here I am using medium article dataset to perfom Topic Modelling. The dataset consist 350 articles related to AI, Machine Learning and Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-spice",
   "metadata": {
    "papermill": {
     "duration": 0.025085,
     "end_time": "2021-04-29T05:08:20.557891",
     "exception": false,
     "start_time": "2021-04-29T05:08:20.532806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploring the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "superb-proposition",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:20.619339Z",
     "iopub.status.busy": "2021-04-29T05:08:20.618590Z",
     "iopub.status.idle": "2021-04-29T05:08:20.773975Z",
     "shell.execute_reply": "2021-04-29T05:08:20.773317Z"
    },
    "papermill": {
     "duration": 0.190735,
     "end_time": "2021-04-29T05:08:20.774116",
     "exception": false,
     "start_time": "2021-04-29T05:08:20.583381",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V_COMMENTS</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mismatch ID number_NRIC</td>\n",
       "      <td>4180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCC2: Match ID and/or Full Legal Name</td>\n",
       "      <td>3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mismatch Full Legal Name – Name Does Not Sound...</td>\n",
       "      <td>2985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mismatch Full Legal Name_Name Does Not Sound S...</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mismatch Full Legal Name_Name does not sound s...</td>\n",
       "      <td>1833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          V_COMMENTS  Counts\n",
       "0                            Mismatch ID number_NRIC    4180\n",
       "1              SCC2: Match ID and/or Full Legal Name    3069\n",
       "2  Mismatch Full Legal Name – Name Does Not Sound...    2985\n",
       "3  Mismatch Full Legal Name_Name Does Not Sound S...    2227\n",
       "4  Mismatch Full Legal Name_Name does not sound s...    1833"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_comments = pd.read_csv(\"generated_all_value_count_comments_nov.csv\")\n",
    "df_all_comments.drop(columns=\"Unnamed: 0\",axis=1,inplace=True)\n",
    "df_all_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-success",
   "metadata": {
    "papermill": {
     "duration": 0.029111,
     "end_time": "2021-04-29T05:08:21.962308",
     "exception": false,
     "start_time": "2021-04-29T05:08:21.933197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploration of text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d2351",
   "metadata": {},
   "source": [
    "Removing special characters\n",
    "\n",
    "1.re.sub(\"\\n\",\"\",x)-line change character to be discarded\n",
    "2.re.sub(\"Name – Name\",\"Name\",x)\n",
    "3.re.sub(\"Name_Name\",\"Name\",x)\n",
    "4. _ with \"\"\n",
    "5 - with \"\"\n",
    "\n",
    "omitting technical values of anchors\n",
    "1. omitting date of birth\n",
    "2. omitting most common names\n",
    "3. omitting id values\n",
    "4. omitting false-hit| true-hit \n",
    "3.Unknown|false hit|False Hit.|False Hit|True Hit|True Hit.|Rationale|Source -omit them\n",
    "omitting Mohd,NORAINI,ABDULLAH,BINTI,system, legal , stated , ABD\n",
    "4 Numbers\n",
    "\n",
    "\n",
    "\n",
    "Removing useless comments\n",
    "\n",
    "1.drop - Match ID and/or Full Legal Name (doubtfull)\n",
    "2.Agreed with analyst recommendation|Agreed with analyst's recommendation|Agreed as per Maker comment|Agreed as per Maker's comment|AGREED WITH MAKER RECOMMENDATION|Agreed With Maker Comments - replace with substring\n",
    "\n",
    "4.CSCDD7|CSCDD4 - Remove comments \n",
    "5CSCDD1 - remove ( still doubtful )\n",
    "6 SCC6|No further review is required by analyst - remove comment\n",
    "7 SC Status : No further review is required by analyst - remove comment\n",
    "8 SC/DEL -remove\n",
    "\n",
    "15 URL removal like - https://edmsfilenet.maybank.com.my/WorkplaceBFE/WcmSignIn.jsp?targetBase=https%3A%2F%2Fedmsfilenet.maybank.com.my%2FWorkplaceBFE&originPort=&originIp=172.31.75.67&targetUrl=WcmDefault.jsp\n",
    "special characters - Mismatch Full Legal Name â€“ Name Does Not Sound Similar ,\n",
    "16 Not removing any special character for now - Mismatch Full Legal Name_Name does not sound similar - watchperson Zhang Ping 张平 vs customer Zhang Peng 张鹏\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2a581830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patt6=re.compile(\"https?://\\S+|www\\.\\S+\",re.IGNORECASE)\n",
    "# # df_all_comments[df_all_comments[\"V_COMMENTS\"].apply(lambda x: len(re.findall(patt6,x))>0)]\n",
    "# ind=df_all_comments[df_all_comments[\"V_COMMENTS\"].str.extract(r\"(https?://\\S+|www\\.\\S+)\")[0].apply(lambda x: pd.notna(x))].index\n",
    "# df_all_comments.loc[ind,\"V_COMMENTS\"].str.extract(r\"(https?://.*\\.com|www\\..*\\.com)\").value_counts().to_csv(\"URL_in_comments.csv\")\n",
    "# # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04de88e",
   "metadata": {},
   "source": [
    "# Pre-processing on Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e554117e",
   "metadata": {},
   "source": [
    "### Step -1 removing noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ded48e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "patt1=re.compile(\"Match ID and/or Full Legal Name\",re.IGNORECASE)\n",
    "# patt2=re.compile(\"Agreed with analyst recommendation|Agreed with analyst's recommendation|Agreed as per Maker comment|Agreed as per Maker's comment\")\n",
    "patt2=re.compile(\"(Agreed|agree) (to|with|as per) (analyst(('s)*)|maker(('s)*)) (comment|recommendation|is recommendation)\",re.IGNORECASE)\n",
    "patt3=re.compile(\"Unknown|false hit\\.*|true hit\\.*|Rationale|Source\",re.IGNORECASE)\n",
    "patt4=re.compile(\"CSCDD7|CSCDD1|CSCDD4\",re.IGNORECASE)\n",
    "patt5=re.compile(\"SCC6|No further review is required by analyst|SC/DEL\",re.IGNORECASE)\n",
    "patt6=re.compile(\"https?://\\S+|www\\.\\S+\",re.IGNORECASE)\n",
    "patt7=re.compile(\"(%s)\"%\"|\".join(cal)[1:],re.IGNORECASE)\n",
    "patt8=re.compile(\"\\s*(Mohd|NORAINI|ABDULLAH|BINTI|system|legal|stated|ABD|mahdzir|bin|khalid|siti|hajar|mohd|sallehudin|mohd|saddam|inie|binti|abdullah|noraini|norliza|binti|othman)\\s*\",re.IGNORECASE)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f61f62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS\"].apply(lambda x: re.sub(\"\\n\",\" \",x)) #1\n",
    "\n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(\"Name – Name\",\"Name\",x))    #2                                \n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(\"Name_Name\",\"Name\",x))      #3                              \n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(\"\\s*_\\s*|\\s*-\\s*|\\s*,\\s*\",\" \",x)) #4,5\n",
    "\n",
    "\n",
    "df_all_comments=df_all_comments[df_all_comments[\"V_COMMENTS_2\"].str.contains(patt1)==False] #7\n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(patt2,\"\",x)) #8\n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(patt3,\"\",x))  #  9\n",
    "df_all_comments=df_all_comments[df_all_comments[\"V_COMMENTS_2\"].str.contains(patt4)==False]        # 10\n",
    "df_all_comments=df_all_comments[df_all_comments[\"V_COMMENTS_2\"].str.contains(patt5)==False]       #11\n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(patt6,\"\",x)) #15\n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(\"[^\\w\\s\\.]|\\d\",\"\",x)) \n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(\"\\d*\",\"\",x))    #date, year, accounts 6\n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(patt7,\"\",x))    # month 6\n",
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x: re.sub(patt8,\" \",x)) # 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "66e067ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "763611b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments_org=df_all_comments.copy()\n",
    "# df_all_comments_org.to_csv(\"Stage_1_comments_after_pre_process_bigram_trigram.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d7d55d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agreed with analyst recommendation|Agreed with analyst's recommendation|Agreed as per Maker comment|Agreed as per Maker's comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a3b1c480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"analyst's\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.sub(\"Agreed with(a*) recommendation\",\"\",\"Agreed with recommendation\")\n",
    "# re.sub(\"Agreed (with|as per) recommendation\",\"\",\"Agreed recommendation\")\n",
    "patt=re.compile(\"Agreed (with|as per) (analyst(('s)*)|maker(('s)*)) (comment|recommendation)\",re.IGNORECASE)\n",
    "re.escape(\"analyst's\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6fca5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments=pd.read_csv(\"Stage_1_comments_after_pre_process_bigram_trigram.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "785e85a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x=re.compile(\"false hit\\.*\",re.IGNORECASE)\n",
    "# re.findall(x,\"false Hit.\")\n",
    "# txt=\"https://edmsfilenet.maybank.com.my/WorkplaceBFE/WcmSignIn.jsp?targetBase=https%3A%2F%2Fedmsfilenet.maybank.com.my%2FWorkplaceBFE&originPort=&originIp=172.31.75.67&targetUrl=WcmDefault.jsp\"\n",
    "\n",
    "# re.findall(\"https?://\\S+|www\\.\\S+\",txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "02ad901f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_all_comments[df_all_comments[\"V_COMMENTS\"].str.contains(\"Mismatch Full Legal Name_Name does not sound similar - watchperson\")].head(1)[\"V_COMMENTS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4e49c317",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  mismatch id number nric\n",
       "2                mismatch full name does not sound similar\n",
       "3                mismatch full name does not sound similar\n",
       "4                mismatch full name does not sound similar\n",
       "5        mismatch yobage. comparison was made between c...\n",
       "                               ...                        \n",
       "13566    mismatch profile watch person reported age  re...\n",
       "13567    mismatch id nric .watch list nric is . as per ...\n",
       "13568    mismatch profile. customer who is software and...\n",
       "13569    mismatch yobage watch person yob is  info from...\n",
       "13570    mismatch profile. watchperson on   sentenced t...\n",
       "Name: V_COMMENTS_2, Length: 13536, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_comments[\"V_COMMENTS_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c88e82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments[\"V_COMMENTS_2\"]=df_all_comments[\"V_COMMENTS_2\"].apply(lambda x : \"\" if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9fd3269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments=df_all_comments[df_all_comments[\"V_COMMENTS_2\"].apply(lambda x : len(x)!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "appreciated-chosen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:22.043249Z",
     "iopub.status.busy": "2021-04-29T05:08:22.042286Z",
     "iopub.status.idle": "2021-04-29T05:08:22.045495Z",
     "shell.execute_reply": "2021-04-29T05:08:22.045969Z"
    },
    "papermill": {
     "duration": 0.055184,
     "end_time": "2021-04-29T05:08:22.046167",
     "exception": false,
     "start_time": "2021-04-29T05:08:21.990983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lowercase the articles \n",
    "df_all_comments.V_COMMENTS = df_all_comments.V_COMMENTS.apply(lambda t : t.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46cfe6e",
   "metadata": {},
   "source": [
    "Need to check whether to remove top x count words and last y count words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-creation",
   "metadata": {
    "papermill": {
     "duration": 0.028515,
     "end_time": "2021-04-29T05:08:22.104041",
     "exception": false,
     "start_time": "2021-04-29T05:08:22.075526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Expanding contractions:** Contractions are the shortened form of the words like it's, hasn't. We expand them for better analysis of our V_COMMENTS data. I have taken these contractions from [Analytics Vidhay's article](http://https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-V_COMMENTS-data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "aboriginal-sacramento",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:22.254972Z",
     "iopub.status.busy": "2021-04-29T05:08:22.221468Z",
     "iopub.status.idle": "2021-04-29T05:08:23.479498Z",
     "shell.execute_reply": "2021-04-29T05:08:23.480083Z"
    },
    "papermill": {
     "duration": 1.347561,
     "end_time": "2021-04-29T05:08:23.480290",
     "exception": false,
     "start_time": "2021-04-29T05:08:22.132729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionary of English Contractions\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4e902bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r\"(ain't|'s|aren't|can't|can't've|'cause|could've|couldn't|couldn't've|didn't|doesn't|don't|hadn't|hadn't've|hasn't|haven't|he'd|he'd've|he'll|he'll've|how'd|how'd'y|how'll|I'd|I'd've|I'll|I'll've|I'm|I've|isn't|it'd|it'd've|it'll|it'll've|let's|ma'am|mayn't|might've|mightn't|mightn't've|must've|mustn't|mustn't've|needn't|needn't've|o'clock|oughtn't|oughtn't've|shan't|sha'n't|shan't've|she'd|she'd've|she'll|she'll've|should've|shouldn't|shouldn't've|so've|that'd|that'd've|there'd|there'd've|they'd|they'd've|they'll|they'll've|they're|they've|to've|wasn't|we'd|we'd've|we'll|we'll've|we're|we've|weren't|what'll|what'll've|what're|what've|when've|where'd|where've|who'll|who'll've|who've|why've|will've|won't|won't've|would've|wouldn't|wouldn't've|y'all|y'all'd|y'all'd've|y'all're|y'all've|you'd|you'd've|you'll|you'll've|you're|you've)\",\n",
       "re.UNICODE)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "contractions_re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c038df3d",
   "metadata": {},
   "source": [
    "### Step-2 expanding contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8e3b12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for expanding contractions\n",
    "def expand_contractions(V_COMMENTS,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, V_COMMENTS)\n",
    "\n",
    "# Expanding Contractions in the V_COMMENTS data\n",
    "df_all_comments.V_COMMENTS = df_all_comments.V_COMMENTS.apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0b5ff",
   "metadata": {},
   "source": [
    "### step -3 removing stopwords after tokenizing using word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-tiffany",
   "metadata": {
    "papermill": {
     "duration": 0.030339,
     "end_time": "2021-04-29T05:08:23.539642",
     "exception": false,
     "start_time": "2021-04-29T05:08:23.509303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Removing Stopwords and Puctuations**: Stopwords are the words that are highly occurred in a language; they do not add any significance to the sentence. \"a,\" \"an,\" \"the,\" \"in\" are some examples of stopwords. So we generally ignore stop words during our NLP task. In some NLP tasks, stop words are also important, but stopwords are unnecessary for topic modeling. We also remove punctuation marks because they are also unnecessary and do not contribute anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "controlled-liberia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:23.603489Z",
     "iopub.status.busy": "2021-04-29T05:08:23.602671Z",
     "iopub.status.idle": "2021-04-29T05:08:23.614738Z",
     "shell.execute_reply": "2021-04-29T05:08:23.613787Z"
    },
    "papermill": {
     "duration": 0.046179,
     "end_time": "2021-04-29T05:08:23.614934",
     "exception": false,
     "start_time": "2021-04-29T05:08:23.568755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ff3a671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d5e9313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(document):\n",
    "    \"Return the articles after remvoing stopwords\"\n",
    "    article_tokens = word_tokenize(document) \n",
    "    filtered_article = [word for word in article_tokens if not word in stop_words] \n",
    "    return \" \".join(filtered_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cc22ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "df_all_comments.V_COMMENTS_2=df_all_comments.V_COMMENTS_2.apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1757dc27",
   "metadata": {},
   "source": [
    "### step-4 removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "vanilla-costume",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:23.679876Z",
     "iopub.status.busy": "2021-04-29T05:08:23.679137Z",
     "iopub.status.idle": "2021-04-29T05:08:23.683028Z",
     "shell.execute_reply": "2021-04-29T05:08:23.682424Z"
    },
    "papermill": {
     "duration": 0.03748,
     "end_time": "2021-04-29T05:08:23.683159",
     "exception": false,
     "start_time": "2021-04-29T05:08:23.645679",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the punctuations which string.punctuation consist :  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(f\"These are the punctuations which string.punctuation consist :  {string.punctuation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7405ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '[%s]' % re.escape(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f5b56587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing Punctuations \n",
    "df_all_comments.V_COMMENTS_2=df_all_comments.V_COMMENTS_2.apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "36c81f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments.V_COMMENTS_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "worse-taste",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:23.749842Z",
     "iopub.status.busy": "2021-04-29T05:08:23.749181Z",
     "iopub.status.idle": "2021-04-29T05:08:33.723596Z",
     "shell.execute_reply": "2021-04-29T05:08:33.724276Z"
    },
    "papermill": {
     "duration": 10.01178,
     "end_time": "2021-04-29T05:08:33.724443",
     "exception": false,
     "start_time": "2021-04-29T05:08:23.712663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #removing digits\n",
    "# df_all_comments.V_COMMENTS_2 = df_all_comments.V_COMMENTS_2.apply(lambda x: re.sub('\\d*','', x))\n",
    "\n",
    "# df_all_comments.V_COMMENTS_2[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-potato",
   "metadata": {
    "papermill": {
     "duration": 0.030692,
     "end_time": "2021-04-29T05:08:33.786349",
     "exception": false,
     "start_time": "2021-04-29T05:08:33.755657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are still some marks like quotation marks, hypen and apostrophe still remaining in the article, we also need to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9618b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments.V_COMMENTS_2 = df_all_comments.V_COMMENTS_2.apply(remove_extra_marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "southeast-chaos",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:33.915012Z",
     "iopub.status.busy": "2021-04-29T05:08:33.892673Z",
     "iopub.status.idle": "2021-04-29T05:08:38.104570Z",
     "shell.execute_reply": "2021-04-29T05:08:38.103948Z"
    },
    "papermill": {
     "duration": 4.287208,
     "end_time": "2021-04-29T05:08:38.104724",
     "exception": false,
     "start_time": "2021-04-29T05:08:33.817516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def remove_extra_marks(article):\n",
    "#     extra_keys = [\"’\",\"—\",\"”\",\"“\"]\n",
    "#     article_tokens = word_tokenize(article) \n",
    "#     filtered_article = [word for word in article_tokens if not word in extra_keys] \n",
    "#     return \" \".join(filtered_article)\n",
    "    \n",
    "# df_all_comments.V_COMMENTS_2 = df_all_comments.V_COMMENTS_2.apply(remove_extra_marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "indoor-certification",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:08:38.170498Z",
     "iopub.status.busy": "2021-04-29T05:08:38.169644Z",
     "iopub.status.idle": "2021-04-29T05:08:38.174453Z",
     "shell.execute_reply": "2021-04-29T05:08:38.173806Z"
    },
    "papermill": {
     "duration": 0.039825,
     "end_time": "2021-04-29T05:08:38.174594",
     "exception": false,
     "start_time": "2021-04-29T05:08:38.134769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing arbitrary example to visulise clean data\n",
    "df_all_comments.V_COMMENTS_2[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9c1cc",
   "metadata": {},
   "source": [
    "## bi-grams /tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cde543ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = df_all_comments.V_COMMENTS_2.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words)\n",
    "\n",
    "\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4a529d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5e452c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# bigram_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "132e3b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "def lemmatization(texts):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5934fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form Bigrams\n",
    "# dfmake_bigrams(data_words_nostops)\n",
    "\n",
    "texts=df_all_comments.V_COMMENTS_2.apply(lambda x: x.split()).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cb5b95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_bigrams=make_bigrams(data_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1028564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_trigrams=make_trigrams(data_words_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a1d74049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_words_bigrams\n",
    "# data_words_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ee18f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "03aca22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mismatch', 'i', 'd', 'number', 'nric']\n"
     ]
    }
   ],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_trigrams)\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c7a53ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "daacdda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z=pickle.load(open(\"dict.sav\",\"rb\"))\n",
    "# class dict1:\n",
    "#     def __init__(self):\n",
    "#         self.id2word=id2word\n",
    "# xt=dict1()\n",
    "# id2word=z.id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5f9d14e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_lemmatized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\local_00147515\\Temp\\1\\ipykernel_1324\\417662115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_lemmatized' is not defined"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "class dict1:\n",
    "    def __init__(self):\n",
    "        self.id2word=id2word\n",
    "\n",
    "\n",
    "z=pickle.load(open(\"dict.sav\",\"rb\"))\n",
    "\n",
    "# xt=dict1()\n",
    "id2word=z.id2word\n",
    "\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba44b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8584dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # Create Dictionary\n",
    "# id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# # Create Corpus\n",
    "# texts = data_lemmatized\n",
    "\n",
    "# # Term Document Frequency\n",
    "# corpus = [id2word.doc2bow(text) for text in texts] \n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments[\"Tokens\"]=data_lemmatized\n",
    "df_all_comments[\"id_2_feature\"]=corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f01066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_all_comments[df_all_comments[\"id_2_feature\"].apply(lambda x: np.any(pd.isna(x)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_best = pickle.load(open(\"lda_model_tfidf_lemmatizer_bi_tri200.30.3.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c8e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "#                                        id2word=id2word,\n",
    "#                                        num_topics=10, \n",
    "#                                        random_state=100,\n",
    "#                                        chunksize=100,\n",
    "#                                        passes=10,\n",
    "#                                        per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90544c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model_best.print_topics())\n",
    "doc_lda = lda_model_best[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4079ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments.loc[155,\"id_2_feature\"]\n",
    "df_all_comments.loc[155,\"Tokens\"]"
   ]
  },
  {
   "attachments": {
    "f941a0a0-3132-4dd6-88d8-2930d44b78c5.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "political-stone",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.039302,
     "end_time": "2021-04-29T05:09:36.450822",
     "exception": false,
     "start_time": "2021-04-29T05:09:36.411520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Latent Dirichlet Allocation[LDA]:  \n",
    "\n",
    "LDA algorithm is an unsupervised learning algorithm that works on a probabilistic statistical model to discover topics that the document contains automatically. <br> \n",
    "This algorithm works on certain assumptions. The assumption is that the document was generated by picking a set of topics and picking a set of words for each topic. In other words, we can say that the document is a probability distribution over the latent topics, and topics are probability distribution over the words.\n",
    "\n",
    "Now let's understand the work methodology of LDA using Plate Diagram:\n",
    "<br>\n",
    "\n",
    "![Smoothed_LDA.png](attachment:f941a0a0-3132-4dd6-88d8-2930d44b78c5.png)\n",
    "             \n",
    "               **Plate Diagram of LDA model**\n",
    "\n",
    "The above image is taken from [Wikipedia](http://https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Smoothed_LDA.png/377px-Smoothed_LDA.png)\n",
    "\n",
    "Here, $\\alpha$ and $\\beta$ are two hyperparameters that we have to initialise manually, and they symbolize per topic distribution($\\alpha$) and per topic word distribution($\\beta$), respectively. And **Z** is the topic for the **N**-th word in document **M**, and **W** is the specific word. We can only see W(specific words) in the documents because it is only an observable variable, and all others are latent.\n",
    "\n",
    "$\\theta$ is the matrix where rows are the documents; columns are topics, and $\\theta(i,j)$ represents the probability of $ith$ document containing $jth$ topic. Similarly, $\\phi$ is the matrix where rows are the topics; columns are words, and $\\phi(i,j)$ represents the probability of $ith$ topic containing $jth$ word. According to the distribution of $\\phi$; **K** individual words are generated for the topics.\n",
    "\n",
    "With the help of this LDA, try to estimate the words that belong to each topic and find the topics in documents accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba60470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(lda_model,open(\"lda_model_lemmatizer_bi_tri.sav\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_model = pickle.load(open(\"lda_model_lemmatizer_bi_tri.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc74994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top words for each topic\n",
    "# top_words_per_topic = []\n",
    "# for topic_id in range(lda_model_best.num_topics):\n",
    "#     top_words = [id2word[word_id] for word_id, prob in lda_model_best.get_topic_terms(topic_id, topn=10)]\n",
    "#     top_words_per_topic.append(top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-impossible",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:09:49.186191Z",
     "iopub.status.busy": "2021-04-29T05:09:49.184760Z",
     "iopub.status.idle": "2021-04-29T05:09:49.200673Z",
     "shell.execute_reply": "2021-04-29T05:09:49.201556Z"
    },
    "papermill": {
     "duration": 0.061738,
     "end_time": "2021-04-29T05:09:49.201834",
     "exception": false,
     "start_time": "2021-04-29T05:09:49.140096",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict1={}\n",
    "# for i,j in zip(range(len(top_words_per_topic)),top_words_per_topic):\n",
    "#     dict1[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e3ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments.drop(\"index\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f6f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_document_topics(corpus)\n",
    "# for i, doc in enumerate(corpus):\n",
    "#     print(\"Document\", i+1)\n",
    "#     print(lda_model_best.get_document_topics(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d58ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "# print('\\nPerplexity : ', lda_model_best.log_perplexity(corpus)) \n",
    "\n",
    "# # Compute Coherence Score\n",
    "# coherence_model_lda = CoherenceModel(model=lda_model_best, texts=data_lemmatized,corpus=corpus, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e96b38",
   "metadata": {},
   "source": [
    "need to work on\n",
    "1)increasing the number of topics  and no. of words in each cloud  -tuning part\n",
    "2)identifying the root word - Lemmatyzing, stemming\n",
    "usage of bi-grams & tri-grams\n",
    "3)topic 3-pre-processing - reomval of names -Mohd,NORAINI,ABDULLAH,BINTI,\n",
    "4)system, legal , stated , ABD\n",
    "\n",
    "doubt - number ,within, SDN BHD , Pvt. Ltd. , Berhad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-flexibility",
   "metadata": {
    "papermill": {
     "duration": 0.04103,
     "end_time": "2021-04-29T05:09:49.365726",
     "exception": false,
     "start_time": "2021-04-29T05:09:49.324696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualising Topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd8a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c00c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensimvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-cuisine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:09:49.457833Z",
     "iopub.status.busy": "2021-04-29T05:09:49.456818Z",
     "iopub.status.idle": "2021-04-29T05:09:53.622001Z",
     "shell.execute_reply": "2021-04-29T05:09:53.622510Z"
    },
    "papermill": {
     "duration": 4.215604,
     "end_time": "2021-04-29T05:09:53.622681",
     "exception": false,
     "start_time": "2021-04-29T05:09:49.407077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-external",
   "metadata": {
    "papermill": {
     "duration": 0.044347,
     "end_time": "2021-04-29T05:09:53.710679",
     "exception": false,
     "start_time": "2021-04-29T05:09:53.666332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To measure how good is our model we can use **perplexity score** and **coherence socre**. The lower score of perplexity is better for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e17adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c9d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_lda = lda_model_best[corpus]\n",
    "# x=lda_model_best.print_topics()\n",
    "# y={}\n",
    "# for i,j in x:\n",
    "#     y[i]=j\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8d408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_all_comments[\"Topic\"]=\"\"\n",
    "# df_all_comments[\"All_Topic_Probabilities\"]=\"\"\n",
    "# df_all_comments[\"Topic No\"]=\"\"\n",
    "# for i, doc in enumerate(corpus):\n",
    "#       topic=sorted(lda_model_best.get_document_topics(doc),key=lambda x: x[1],reverse=True)[0][0]\n",
    "#       df_all_comments[\"Topic No\"].loc[i]=topic  \n",
    "#       df_all_comments[\"Topic\"].loc[i]=y[topic]\n",
    "#       df_all_comments[\"All_Topic_Probabilities\"].loc[i]=lda_model_best.get_document_topics(doc)\n",
    "# #     .index(max(dict(lda_model_best.get_document_topics(doc)).values()))\n",
    "# #      y[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e77a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments[\"Topic words\"]=df_all_comments[\"Topic No\"].apply(lambda x: dict1[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments.to_csv(\"Output_of_topic_modelling.csv\")\n",
    "# len(corpus)\n",
    "# df_all_comments.loc[221574:,[\"V_COMMENTS_2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71006d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments[df_all_comments[\"All_Topic_Probabilities\"].apply(lambda x:type(x)==str )][\"All_Topic_Probabilities\"]\n",
    "# model.get_document_topics(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf9b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments.to_csv(\"Output_of_topic_modelling_20_bow_bi_tri.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafee679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6014816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(lda_model,open(\"lda_model_l_bi_tri.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pickle.load(open(\"lda_model_lemmatizer_bi_gram.sav\",\"rb\"))\n",
    "# import pickle\n",
    "# model = pickle.load(open(\"lda_model.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "valued-explosion",
   "metadata": {
    "papermill": {
     "duration": 0.043901,
     "end_time": "2021-04-29T05:10:02.880134",
     "exception": false,
     "start_time": "2021-04-29T05:10:02.836233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is mainly focused on LDA implementation for coherence score you can read this [medium article](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c3b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:09:53.803300Z",
     "iopub.status.busy": "2021-04-29T05:09:53.802561Z",
     "iopub.status.idle": "2021-04-29T05:10:02.790129Z",
     "shell.execute_reply": "2021-04-29T05:10:02.790630Z"
    },
    "papermill": {
     "duration": 9.036255,
     "end_time": "2021-04-29T05:10:02.790834",
     "exception": false,
     "start_time": "2021-04-29T05:09:53.754579",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f533bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f54ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fb3b40b",
   "metadata": {},
   "source": [
    "### Using tf-idf for feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f60985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e58958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tfidf = TfidfModel(corpus, smartirs='ntc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5763f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf[corpus][1])\n",
    "tfidf_corpus=tfidf[corpus]\n",
    "# corpus_example = [[(id2word[id], freq) for id, freq in cp] for cp in corpus[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e50657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments[\"TFIDF_Feature\"]=[doc for doc in tfidf_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c003c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1cb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9357395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_tfidf_model = gensim.models.ldamodel.LdaModel(corpus=tfidf_corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=10, \n",
    "#                                            random_state=100,\n",
    "#                                            update_every=1,\n",
    "#                                            chunksize=100,\n",
    "#                                            passes=10,\n",
    "#                                            alpha='symmetric',\n",
    "#                                            per_word_topics=True,\n",
    "#                                            eta = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e46580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa719c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model_best.print_topics())\n",
    "# doc_lda = lda_tfidf_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [lda_model_best[doc] for doc in tfidf_corpus ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8690f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_document_topics(corpus)\n",
    "for i, doc in enumerate(tfidf_corpus):\n",
    "    print(\"Document\", i+1)\n",
    "    print(lda_model_best.get_document_topics(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b35c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(lda_tfidf_model,open(\"lda_model_tfidf_lemmatizer_bi_tri.sav\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b14a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_tfidf_model1= pickle.load(open(\"lda_model_tfidf_lemmatizer_bi_tri.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ee21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Compute Perplexity\n",
    "# print('\\nPerplexity : ', lda_tfidf_model1.log_perplexity(corpus)) \n",
    "\n",
    "# # Compute Coherence Score\n",
    "# coherence_model_lda_tf_idf = CoherenceModel(model=lda_tfidf_model1, texts=data_lemmatized,corpus=tfidf_corpus, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda_tf_idf.get_coherence()\n",
    "# print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ab949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity : ', lda_model_best.log_perplexity(corpus)) \n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda_tf_idf = CoherenceModel(model=lda_model_best, texts=data_lemmatized,corpus=tfidf_corpus, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda_tf_idf.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbddb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_per_topic = []\n",
    "for topic_id in range(lda_model_best.num_topics):\n",
    "    top_words = [id2word[word_id] for word_id, prob in lda_model_best.get_topic_terms(topic_id, topn=10)]\n",
    "    top_words_per_topic.append(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2={}\n",
    "for i,j in zip(range(len(top_words_per_topic)),top_words_per_topic):\n",
    "    dict2[i]=j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c80690",
   "metadata": {
    "papermill": {
     "duration": 0.043901,
     "end_time": "2021-04-29T05:10:02.880134",
     "exception": false,
     "start_time": "2021-04-29T05:10:02.836233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is mainly focused on LDA implementation for coherence score you can read this [medium article](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_lda = model[corpus]\n",
    "x=lda_model_best.print_topics()\n",
    "y={}\n",
    "for i,j in x:\n",
    "    y[i]=j\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c30193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all_comments[\"Topic_tfidf_lda\"]=\"\"\n",
    "df_all_comments[\"All_Topic_tfidf_Probabilities\"]=\"\"\n",
    "df_all_comments[\"TF_tfidf_Topic_No\"]=\"\"\n",
    "for i, doc in enumerate(tfidf_corpus):\n",
    "      topic=sorted(lda_model_best.get_document_topics(doc),key=lambda x: x[1],reverse=True)[0][0]\n",
    "      df_all_comments[\"TF_tfidf_Topic_No\"].loc[i]=topic  \n",
    "      df_all_comments[\"Topic_tfidf_lda\"].loc[i]=y[topic]\n",
    "      df_all_comments[\"All_Topic_tfidf_Probabilities\"].loc[i]=lda_model_best.get_document_topics(doc)\n",
    "#     .index(max(dict(model.get_document_topics(doc)).values()))\n",
    "#      y[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8628aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments[\"TF IDF Topic words\"]=df_all_comments[\"TF_tfidf_Topic_No\"].apply(lambda x: dict2[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a3fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments[\"Topic_tfidf_lda\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_comments.to_csv(\"Output_of_topic_modelling_final_20_bi_tri_nov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd64398",
   "metadata": {},
   "source": [
    "## the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64361b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# importing all necessary modules\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.read_csv(\"Output_of_topic_modelling_final_20_bi_tri_nov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()\n",
    "df_new.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62669fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new[\"Topic\"].apply(lambda x:pd.isna(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1042fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"V_COMMENTS_2\"]=df_new[\"V_COMMENTS_2\"].apply(lambda x:\"\" if pd.isna(x) else x)\n",
    "df_new=df_new[df_new[\"V_COMMENTS_2\"].apply(lambda x: len(x)!=0)]\n",
    "\n",
    "df_new[\"V_COMMENTS_2\"].apply(lambda x: type(x)).unique()\n",
    "\n",
    "# df_new[\"Topic\"].apply(lambda x:pd.isna(x))\n",
    "df_new[\"Tokens\"]=df_new[\"Tokens\"].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "\n",
    "df_new=df_new[df_new[\"Tokens\"].apply(lambda x: len(x)!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"TF IDF Topic words\"]=df_new[\"TF IDF Topic words\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db18c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new[\"V_COMMENTS_2\"]=df_new[\"V_COMMENTS_2\"].apply(lambda x:\"\" if pd.isna(x) else x)\n",
    "# df_new[\"Tokens\"]=df_new[\"Tokens\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"TF IDF Topic words\"]=df_new[\"TF IDF Topic words\"].apply(lambda x:[i.split(\"_\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabf537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"TF IDF Topic words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2232b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in df_new[\"TF IDF Topic words\"]:\n",
    "    l1=[]\n",
    "    for word in i:\n",
    "        for j in word:\n",
    "            l1.append(j)\n",
    "    l.append(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fe537",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"TF IDF Topic words\"]=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3=df_new[\"Tokens\"].to_list()\n",
    "l4=df_new[\"TF IDF Topic words\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d222e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3.extend(l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f5bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1= gensim.models.Word2Vec(l3, min_count=1,\n",
    "                                vector_size=100, window=5,sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(,)\n",
    "import pickle\n",
    "# pickle.dump(model1,open(\"word2vec.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbe112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new[\"Vect\"]=df_new[\"Tokens\"].apply(lambda x:np.sum(np.array([model1.wv[i] for i in x]),axis=0)/(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210cf444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new[\"TF IDF Topic words\"].apply(lambda x:[j for j in i for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"Vect 2\"]=df_new[\"TF IDF Topic words\"].apply(lambda x:np.sum(np.array([model1.wv[i] for i in x]),axis=0)/(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983904c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ffb52a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new[\"sim_score\"]=df_new[[\"Vect\",\"Vect 2\"]].apply(lambda x: cosine_similarity([x[0]],[x[1]]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8614c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new[\"sim_score\"]=df_new[\"sim_score\"].apply(lambda x: x[0][0])\n",
    "df_new[\"sim_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b37140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"sim_score\"]=df_new[\"sim_score\"].apply(lambda x: np.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da602571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"sim_score\"].apply(lambda x: type(x)==np.ndarray)][\"V_COMMENTS_2\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1994ccc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_new.index,df_new[\"sim_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_new[\"sim_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f393530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.boxplot(df_new[\"sim_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318575e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1,q2,q3=np.percentile(df_new[\"sim_score\"],[25,50,75])\n",
    "print(q1,q2,q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[df_new[\"sim_score\"].apply(lambda x: x<y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b102c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=q1-1.5*(q3-q1)\n",
    "df_new[df_new[\"sim_score\"].apply(lambda x: x<y)].to_csv(\"Outliers_word2vec_cbow_nov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45411ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1=df_new[df_new[\"sim_score\"].apply(lambda x: x<y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd743b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ddb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1[\"TF_tfidf_Topic_No\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f395a",
   "metadata": {},
   "source": [
    "# The end -2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-reduction",
   "metadata": {
    "papermill": {
     "duration": 0.045197,
     "end_time": "2021-04-29T05:10:02.969489",
     "exception": false,
     "start_time": "2021-04-29T05:10:02.924292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tuning hyperparameters:\n",
    "\n",
    "We can try out different number of topics, different values of alpha and beta(eta) to increse the conharence score. High conherence score is good for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coherence_score(n, alpha, beta):\n",
    "    lda_tfidf_model2 = gensim.models.ldamodel.LdaModel(corpus=tfidf_corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=n, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=alpha,\n",
    "                                           per_word_topics=True,\n",
    "                                           eta = beta)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda_tf_idf = CoherenceModel(model=lda_tfidf_model2, texts=data_lemmatized,corpus=tfidf_corpus, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda_tf_idf.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_lda)\n",
    "    \n",
    "    \n",
    "    return (coherence_lda,lda_tfidf_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-caribbean",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:10:03.072116Z",
     "iopub.status.busy": "2021-04-29T05:10:03.068147Z",
     "iopub.status.idle": "2021-04-29T05:38:41.156581Z",
     "shell.execute_reply": "2021-04-29T05:38:41.157105Z"
    },
    "papermill": {
     "duration": 1718.143175,
     "end_time": "2021-04-29T05:38:41.157321",
     "exception": false,
     "start_time": "2021-04-29T05:10:03.014146",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#list containing various hyperparameters\n",
    "no_of_topics = [15]\n",
    "alpha_list = ['symmetric',0.3,0.5,0.7]\n",
    "beta_list = ['auto',0.3,0.5,0.7]\n",
    "\n",
    "\n",
    "for n in no_of_topics:\n",
    "    for alpha in alpha_list:\n",
    "        for beta in beta_list:\n",
    "            coherence_score,model = calculate_coherence_score(n, alpha, beta)\n",
    "            print(f\"n : {n} ; alpha : {alpha} ; beta : {beta} ; Score : {coherence_score}\")\n",
    "            \n",
    "            \n",
    "        \n",
    "            pickle.dump(model,open(\"lda_model_tfidf_lemmatizer_bi_tri\"+str(n)+str(alpha)+str(beta)+\".sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd3d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list containing various hyperparameters\n",
    "no_of_topics = [20]\n",
    "alpha_list = ['symmetric',0.3,0.5,0.7]\n",
    "beta_list = ['auto',0.3,0.5,0.7]\n",
    "\n",
    "\n",
    "for n in no_of_topics:\n",
    "    for alpha in alpha_list:\n",
    "        for beta in beta_list:\n",
    "            coherence_score,model = calculate_coherence_score(n, alpha, beta)\n",
    "            print(f\"n : {n} ; alpha : {alpha} ; beta : {beta} ; Score : {coherence_score}\")\n",
    "            \n",
    "            \n",
    "        \n",
    "            pickle.dump(model,open(\"lda_model_tfidf_lemmatizer_bi_tri_20_\"+str(n)+str(alpha)+str(beta)+\".sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-tract",
   "metadata": {
    "papermill": {
     "duration": 0.073236,
     "end_time": "2021-04-29T05:38:41.450120",
     "exception": false,
     "start_time": "2021-04-29T05:38:41.376884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Final LDA Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-toronto",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:38:41.609483Z",
     "iopub.status.busy": "2021-04-29T05:38:41.608470Z",
     "iopub.status.idle": "2021-04-29T05:39:10.633039Z",
     "shell.execute_reply": "2021-04-29T05:39:10.632386Z"
    },
    "papermill": {
     "duration": 29.10995,
     "end_time": "2021-04-29T05:39:10.633175",
     "exception": false,
     "start_time": "2021-04-29T05:38:41.523225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 14\n",
    "alpha = 0.3\n",
    "beta = \"auto\"\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=n, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=alpha,\n",
    "                                           per_word_topics=True,\n",
    "                                           eta = beta)\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, V_COMMENTS_2s=tokeize_article, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-partner",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-29T05:39:10.874305Z",
     "iopub.status.busy": "2021-04-29T05:39:10.842079Z",
     "iopub.status.idle": "2021-04-29T05:39:15.415251Z",
     "shell.execute_reply": "2021-04-29T05:39:15.415777Z"
    },
    "papermill": {
     "duration": 4.707214,
     "end_time": "2021-04-29T05:39:15.415945",
     "exception": false,
     "start_time": "2021-04-29T05:39:10.708731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-easter",
   "metadata": {
    "papermill": {
     "duration": 0.073022,
     "end_time": "2021-04-29T05:38:41.303366",
     "exception": false,
     "start_time": "2021-04-29T05:38:41.230344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The highest coherence score is : 0.4962 for number of topics = 14  alpha = 0.3 and beta = auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-buyer",
   "metadata": {
    "papermill": {
     "duration": 0.077251,
     "end_time": "2021-04-29T05:39:15.571690",
     "exception": false,
     "start_time": "2021-04-29T05:39:15.494439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa24b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3ea61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc433c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5955db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6950f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
